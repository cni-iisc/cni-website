---

layout: highlight_page # Do not change this portion

title: Machine Learnig-based Spatial Reuse for Wireless Networks


speaker: Saurabh Kumar Verma

img: assets/img/highlights/2021/saurabhkumarverma2021.png

year: 2021

category: mtech #should have either mtech or phd

report_video: 87gn2wNM8PQ

---

**Research**

This work studies multi-armed bandits formulation based Spatial Reuse to improve the performance
of wireless network in dense deployed areas. Due to immense popularity of wireless network, Dense
and uncoordinated deployments of wireless networks are typical in next-generation, resulting in
inefficient resource utilization and poor performance of WNs. This work propose a method to enable
Spatial Reuse (SR) to solve this problem using entirely decentralized systems. This work concentrate
on dynamic channel allocation (DCA) and Transmission Power Control (TPC) to allow networks to
learn their ideal configuration. I use Reinforcement Learning (RL), specifically the Multi-Armed Bandits (MABs)[1] algorithm, to solve this problem. In this research, I examine the performance of the
epsilon-greedy, EXP3[2], UCB[3], and Thompson sampling[4] action selections to study explorationexploitation trade-offs. Furthermore, I investigate the consequences of selecting actions concurrently
in an adversarial context (i.e., concurrently) and compare it to a sequential method. My results show
that even when learners have no information about surrounding networks and Wireless Networks
(WNs) act selfishly, the network can achieve optimal proportional fairness. Individual networks’
throughput is variable over time, particularly for ϵ-greedy and EXP3. Unlike UCB and Thompson
sampling, these techniques operate based on the total experienced reward rather than its distribution.
Contributions to CNI
I have attended various sessions organized by the CNI department IISc Banglore. I have demonstrated
MTech thesis work on " Machine Learning-Based Spatial Reuse in Wireless network" in Mid review.
References

[1] Sébastien Bubeck and Nicolo Cesa-Bianchi. Regret analysis of stochastic and nonstochastic
multi-armed bandit problems. arXiv preprint arXiv:1204.5721, 2012.

[2] Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E Schapire. Gambling in a rigged
casino: The adversarial multi-armed bandit problem. In Proceedings of IEEE 36th Annual
Foundations of Computer Science, pages 322–331. IEEE, 1995.

[3] Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit
problem. Machine learning, 47(2):235–256, 2002.

[4] William R Thompson. On the likelihood that one unknown probability exceeds another in view
of the evidence of two samples. Biometrika, 25(3-4):285–294, 1933.